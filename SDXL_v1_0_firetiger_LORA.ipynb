{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPXlHsKPYT2dzxXieywPHWL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trentclat/SDXL-LoRA/blob/main/SDXL_v1_0_firetiger_LORA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all pips\n",
        "!pip install --upgrade diffusers[torch] transformers accelerate peft safetensors huggingface_hub\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "#install any extras the script needs\n",
        "!pip install -r diffusers/examples/text_to_image/requirements.txt\n",
        "!pip uninstall -y diffusers\n",
        "!pip install --upgrade git+https://github.com/huggingface/diffusers.git@main\n",
        "!pip install --upgrade accelerate transformers safetensors\n",
        "# Pull PEFT straight from main so it’s ≥0.15.0\n",
        "!pip install --upgrade git+https://github.com/huggingface/peft.git@main\n",
        "!pip uninstall -y xformers\n",
        "\n",
        "\n",
        "# imports\n",
        "import torch\n",
        "import json\n",
        "\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# pre configure accel defaults\n",
        "!accelerate config default --mixed_precision=\"fp16\" --num_processes=1 --num_machines=1 --dynamo_backend=\"no\"\n",
        "\n",
        "# device setup\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"✅ Environment ready. PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}\")\n"
      ],
      "metadata": {
        "id": "EcUEv3KOfLj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HF token connection\n",
        "\n",
        "from google.colab import userdata\n",
        "mykey = userdata.get('worktoken')\n",
        "print(mykey)"
      ],
      "metadata": {
        "id": "hp1bl-a4fTDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HF token and login\n",
        "\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get(\"worktoken\")\n",
        "login(token=hf_token)"
      ],
      "metadata": {
        "id": "SjHhCmanh6ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "scH-lgyjLv9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load SDXL base & refiner\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "pipe_base = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype = torch.float16,\n",
        ").to(device)\n",
        "\n",
        "pipe_refiner = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "yW1Z6vm0h76n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach LoRA to base UNet\n",
        "\n",
        "lora_cfg = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "pipe_base.unet = get_peft_model(pipe_base.unet, lora_cfg)\n"
      ],
      "metadata": {
        "id": "mpu9uECmbECV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for source images\n",
        "import os\n",
        "\n",
        "image_dir = \"/content/drive/MyDrive/LoRA_Prep/stdized_firetiger\"\n",
        "image_paths = [\n",
        "    os.path.join(image_dir, f)\n",
        "    for f in os.listdir(image_dir)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "print(f\"Found {len(image_paths)} images.\")\n"
      ],
      "metadata": {
        "id": "pnfCOErqbFV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "\n",
        "# 1) hand‐code a Python dict\n",
        "captions = {\n",
        "    \"1347816_Firetiger_MS.jpg\": \"xyz_fire_tiger, hooks_diagonal_left_downward, side_view, studio_shot, white_background\",\n",
        "    \"1373962_Firetiger_MS.jpg\": \"xyz_fire_tiger, bold_sharp_stripes, side_view, studio_shot, white_background\",\n",
        "    \"1373966_Firetiger_MS.jpg\": \"xyz_fire_tiger, bold_sharp_stripes, side_view, studio_shot, white_background\",\n",
        "    \"1454428_Firetiger_MS.jpg\": \"xyz_fire_tiger, side_view, studio_shot, white_background\",\n",
        "    \"1454429_Firetiger_MS.jpg\": \"xyz_fire_tiger, jointed_lure, side_view, studio_shot, white_background\",\n",
        "    \"1523078_Firetiger_11_MS.jpg\": \"xyz_fire_tiger, three_treble_hooks, studio_shot, white_background\",\n",
        "    \"1573537_1572465_MS.jpg\": \"xyz_fire_tiger, black_eye, side_view, studio_shot, white_background\",\n",
        "    \"1573537_1572525_MS.jpg\": \"xyz_fire_tiger, black_eye, side_view, studio_shot, white_background\",\n",
        "    \"1601024_1600951_MS.jpg\": \"xyz_fire_tiger, side_view, studio_shot, white_background\",\n",
        "    \"1601024_1600971_MS.jpg\": \"xyz_fire_tiger, three_treble_hooks, studio_shot, white_background\",\n",
        "    \"1601025_1600757_MS.jpg\": \"xyz_fire_tiger, single_dorsal_hook, side_view, studio_shot, white_background\",\n",
        "    \"1624396_1623961_MS.jpg\": \"xyz_fire_tiger, bold_sharp_stripes, no_hooks, side_view, studio_shot, white_background\",\n",
        "    \"1624396_1624113_MS.jpg\": \"xyz_fire_tiger, bold_sharp_stripes, no_hooks, side_view, studio_shot, white_background\",\n",
        "    \"1624399_1624251_MS.jpg\": \"xyz_fire_tiger, single_dorsal_hook, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of deep_hit_stick_1.jpg\": \"xyz_fire_tiger, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of deep_hit_stick_2.jpg\": \"xyz_fire_tiger, three_treble_hooks, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of finisher.jpg\": \"xyz_fire_tiger, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of flicker_minnow.jpg\": \"xyz_fire_tiger, hooks_diagonal_left_downward, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of flicker_shad_jointed.jpg\": \"xyz_fire_tiger, jointed_lure, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of flicker_shad_shallow.jpg\": \"xyz_fire_tiger, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of flicker_shad.jpg\": \"xyz_fire_tiger, hooks_diagonal_left_downward, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of hit_stick_1.jpg\": \"xyz_fire_tiger, three_treble_hooks, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of hit_stick_2.jpg\": \"xyz_fire_tiger, side_view, studio_shot, white_background\",\n",
        "    \"Copy of Copy of hit_stick_3.jpg\": \"xyz_fire_tiger, single_treble_hook, side_view, studio_shot, white_background\",\n",
        "    \"Copy of deep_hit_stick_1.jpg\": \"xyz_fire_tiger, side_view, studio_shot, white_background\",\n",
        "    \"Copy of deep_hit_stick_2.jpg\": \"xyz_fire_tiger, three_treble_hooks, studio_shot, white_background\",\n",
        "}\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/LoRA_Prep/stdized_firetiger\"\n",
        "out_path = os.path.join(data_dir, \"metadata.jsonl\")\n",
        "\n",
        "with open(out_path, \"w\") as f:\n",
        "    for fn, cap in captions.items():\n",
        "        img_path = os.path.join(data_dir, fn)\n",
        "        if os.path.exists(img_path):\n",
        "            entry = {\"image_file_name\": fn, \"text\": cap}\n",
        "            f.write(json.dumps(entry) + \"\\n\")\n",
        "        else:\n",
        "            print(\"Missing:\", fn)\n",
        "\n",
        "print(\"metadata.jsonl generated at:\", out_path)\n"
      ],
      "metadata": {
        "id": "mAvvIKD7bfsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# free refiner and clear GPU cache\n",
        "del pipe_refiner\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Freed refiner and cleared GPU cache.\")"
      ],
      "metadata": {
        "id": "jdTX3MbsTHMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "accelerate launch \\\n",
        "  --num_processes=1 \\\n",
        "  --num_machines=1 \\\n",
        "  --mixed_precision=\"bf16\" \\\n",
        "  --dynamo_backend=\"no\" \\\n",
        "  /content/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
        "  --pretrained_vae_model_name_or_path=\"stabilityai/sdxl-vae\" \\\n",
        "  --train_data_dir=\"/content/drive/MyDrive/LoRA_Prep/stdized_firetiger\" \\\n",
        "  --image_column=\"image\" \\\n",
        "  --caption_column=\"text\" \\\n",
        "  --resolution=896 \\\n",
        "  --random_flip \\\n",
        "  --train_batch_size=2 \\\n",
        "  --gradient_accumulation_steps=8 \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --learning_rate=5e-5 \\\n",
        "  --output_dir=\"/content/drive/MyDrive/LoRA/LoRA_Model/SDXL_firetiger\" \\\n",
        "  --rank=16 \\\n",
        "  --resume_from_checkpoint=\"/content/drive/MyDrive/LoRA/LoRA_Model/SDXL_firetiger/checkpoint-1000\"\n"
      ],
      "metadata": {
        "id": "oLsmwOeh19ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionXLPipeline\n",
        "import torch\n",
        "\n",
        "# 2) Load your first LoRA (e.g. shape adapter)\n",
        "pipe_base.load_lora_weights(\"/content/drive/MyDrive/LoRA/LoRA_Model/SDXL_shape/pytorch_lora_weights.safetensors\")\n",
        "\n",
        "# 3) Load your second LoRA (e.g. color adapter)\n",
        "pipe_base.load_lora_weights(\"/content/drive/MyDrive/LoRA/LoRA_Model/SDXL_firetiger/pytorch_lora_weights.safetensors\")\n",
        "\n",
        "# 4) Now both adapters are “stacked” on top of the base model:\n",
        "prompt = \"A single photorealistic xyz_firetiger lure held in center of human hand. Hand centerfold with a lake side background\"\n",
        "image = pipe_base(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
        "\n",
        "image.save(\"/content/drive/MyDrive/LoRA/LoRA_Output/sdxl_outputs/demo_handshot_firetiger_combined_loras_test.png\")\n"
      ],
      "metadata": {
        "id": "SJ2NEGtq9KJS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}